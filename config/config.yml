default:
  logger: &logger
    name: node_promise_scraper
    #level 'CRITICAL','ERROR','WARNING','INFO','DEBUG'
  mongo: &mongo
    host: 127.0.0.1
    port: 27017
  beanstalkd: &beanstalkd
    host: 127.0.0.1
    port: 11300

development:
  scraper:
    #Number of chance given to a failed job
    retry_count: 0
    #Maximum global socket per process
    globalMaxSockets: 6
    default_request_timeout_seconds: 5
    #Number of WebScraperController per process
    controller_count: 20
    #cluster_mode = 0:
    #  there will be only one WebScraperProcess
    #cluster_mode = 1:
    #  there will be multiple WebScraperProcess in same machine depends on number of CPU
    cluster_mode: 1
  logger:
    <<: *logger
    file_log:
      filename: debug_log.log
      level: DEBUG
    stdout_log:
      level: DEBUG
  mongo:
    <<: *mongo
    database: proscraper_development
  beanstalkd:
    <<: *beanstalkd

production:
  scraper:
    #Number of chance given to a failed job
    retry_count: 3
    #Maximum global socket per process
    globalMaxSockets: 6
    default_request_timeout_seconds: 5
    #Number of WebScraperController per process
    controller_count: 20
    #cluster_mode = 0:
    #  there will be only one WebScraperProcess
    #cluster_mode = 1:
    #  there will be multiple WebScraperProcess in same machine depends on number of CPU
    cluster_mode: 1
  logger:
    <<: *logger
    file_log:
      filename: productin_log.log
      level: WARN
    stdout_log:
      level: WARN
  mongo:
    <<: *mongo
    database: proscraper_development
  beanstalkd:
    <<: *beanstalkd
